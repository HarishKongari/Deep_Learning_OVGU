{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ohifgx1bwWJs",
        "colab_type": "code",
        "outputId": "0604a997-5747-40c1-fd76-75cb6238701b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzMdc92Ywfc0",
        "colab_type": "code",
        "outputId": "c1f736f5-7065-4a8a-9de3-998aa50bf4b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "\n",
        "#plt.imshow(train_images[0], cmap=\"Greys_r\")\n",
        "\n",
        "#process traindata\n",
        "train_images = (train_images.astype(np.float32) / 255.).reshape((-1, 784))\n",
        "train_labels = train_labels.astype(np.int32)\n",
        "train_data = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "train_data = train_data.shuffle(1000)\n",
        "train_data = train_data.repeat()\n",
        "train_data = train_data.batch(128)\n",
        "iterator = iter(train_data)\n",
        "\n",
        "\n",
        "#process textdata\n",
        "test_images = (test_images.astype(np.float32) / 255.).reshape((-1, 784))\n",
        "test_labels = test_labels.astype(np.int32)\n",
        "\n",
        "\n",
        "train_steps = 2000\n",
        "learning_rate = 0.1\n",
        "\n",
        "\n",
        "W1 = tf.Variable(tf.compat.v1.random.normal([784,500], stddev=0.1))\n",
        "b1 = tf.Variable(tf.constant(0.1,shape=[500]))\n",
        "\n",
        "W2 = tf.Variable(np.zeros([500, 10]).astype(np.float32))\n",
        "b2 = tf.Variable(np.zeros(10, dtype=np.float32))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for step in range(train_steps):\n",
        "    img_batch, lbl_batch = next(iterator)\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = tf.matmul(tf.nn.relu(tf.matmul(img_batch, W1) + b1),W2)+b2\n",
        "        xent = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "           logits=logits, labels=lbl_batch))\n",
        "    grads = tape.gradient(xent, [W1,b1,W2, b2])\n",
        "    W1.assign_sub(learning_rate * grads[0])\n",
        "    b1.assign_sub(learning_rate * grads[1])\n",
        "    W2.assign_sub(learning_rate * grads[2])\n",
        "    b2.assign_sub(learning_rate * grads[3])\n",
        "    \n",
        "    if not step % 200:\n",
        "        preds = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
        "        acc = tf.reduce_mean(tf.cast(tf.equal(preds, lbl_batch),\n",
        "                             tf.float32))\n",
        "        print(\"Loss: {} Accuracy: {}\".format(xent, acc))\n",
        "\n",
        "        \n",
        "test_preds = tf.argmax(tf.matmul(tf.nn.relu(tf.matmul(test_images, W1) + b1),W2)+b2, axis=1,\n",
        "                       output_type=tf.int32)\n",
        "acc = tf.reduce_mean(tf.cast(tf.equal(test_preds, test_labels),\n",
        "                             tf.float32))\n",
        "print(acc)\n",
        "\n",
        "#1. shuffle/batch/repeat: the data is first shuffled, and then divided into batches, and finally repeated. \n",
        "\n",
        "#2.shuffle/repeat/batch:The difference between \"1.\" and \"2.\" is that if the samples in an epoch cant be divided\n",
        "# by the size of the batch, \"1.\" will leave a small \"tail\" in each epoch, and 2. will leave only one epoch \n",
        "#at the end of epochs\n",
        "\n",
        "#3.batch/shuffle/repeat : .shuffle after .batch, it will shuffle the batch order , but it will not schuffle the \n",
        "#data in each batch.\n",
        "\n",
        "#4.batch/repeat/shuffle : only batch order will be shuffled, the data in each batch will not be shuffled,and \n",
        "#the batches between epoch will be shuffled (when some batches appear twice, other batches heve not appeared yet),\n",
        "\n",
        "#5.repeat/shuffle/batch/ : the data between epoch will be shuffled (when some data appears twice, other data has \n",
        "#not appeared yet)\n",
        "\n",
        "#6.repeat/batch/shuffleï¼šonly the oder of the batchs will be shuffled.The difference between \"3.\" and \"6.\" is that \n",
        "#if the samples in an epoch cant be divided by the size of the batch, \"2.\" will leave a small \"tail\" in each epoch, \n",
        "#and 5. will leave only one epoch at the end of epochs\n",
        "\n",
        "#i think \"shuffle/repeat/batch\" is the most sensible for training neural networks, the data in each epoch will be shuffled,\n",
        "#and there is only one \"tail\" at the end of epochs, if the samples in an epoch cant be divided by the size of the batch.\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 2.3025853633880615 Accuracy: 0.140625\n",
            "Loss: 0.35939326882362366 Accuracy: 0.890625\n",
            "Loss: 0.31237682700157166 Accuracy: 0.9296875\n",
            "Loss: 0.25450196862220764 Accuracy: 0.9375\n",
            "Loss: 0.33655261993408203 Accuracy: 0.890625\n",
            "Loss: 0.2841366231441498 Accuracy: 0.9140625\n",
            "Loss: 0.18425258994102478 Accuracy: 0.9453125\n",
            "Loss: 0.13215544819831848 Accuracy: 0.96875\n",
            "Loss: 0.14936870336532593 Accuracy: 0.9609375\n",
            "Loss: 0.2092491090297699 Accuracy: 0.9296875\n",
            "tf.Tensor(0.9565, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7vMZnRQWELf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}